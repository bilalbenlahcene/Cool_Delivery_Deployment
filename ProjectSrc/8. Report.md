# Secure Cloud Architecture — Project Report

## Introduction

In today's digital era, organizations are increasingly adopting cloud technologies to enhance scalability, availability, and cost-effectiveness. This transition, while beneficial, introduces significant security challenges. The purpose of this report is to document the design and implementation of a secure cloud architecture for the fictional web application  **Cool Delivery** , in alignment with the pedagogical goals of the Secure Cloud Architecture module.

This document serves as both a technical and pedagogical deliverable. It is designed to be comprehensive, professional, and understandable to both technical and non-technical audiences, following a contract-style format with detailed technical analysis, structured configurations, screenshots, and security justifications.

## Context

**Cool Delivery** is a web-based logistics solution comprising a static frontend (HTML/CSS), a dynamic backend (Flask API), and a MongoDB database. The company is undergoing a digital transformation with the aim of migrating its application to a secure cloud infrastructure on AWS.

In the scope of this university project, we simulate the deployment of a secure cloud infrastructure using AWS (Amazon Web Services) while applying industry-grade security principles and best practices. Each configuration and deployment step is meticulously documented and justified.

## Project Objectives

1. Design and document a secure cloud architecture aligned with AWS best practices.
2. Deploy core services including compute, storage, monitoring, and security controls.
3. Demonstrate layered security (defense-in-depth) across the architecture.
4. Provide a professional-grade final report and presentation.
5. Validate each deployment step with screenshots and detailed commentary.

## Methodology

The architecture is developed using a modular and layered approach, based on the "Well-Architected Framework" and real-world cloud security practices. Each step includes:

* **Design rationale and service overview**
* **Exact AWS configuration (GUI + CLI references)**
* **Security analysis and mitigations**
* **Screenshots and visual proofs**
* **Troubleshooting steps and remediation logs**

The project is divided into 8 key steps:

1. **Compute Layer** — EC2 instance simulating backend.
2. **Frontend Delivery** — S3 bucket + CloudFront + AWS WAF.
3. **Monitoring & Detection** — CloudTrail, CloudWatch, GuardDuty.
4. **IAM & Policies** — IAM Users, Groups, MFA.
5. **System Hardening** — Security agents and audits.
6. **Advanced Logging** — S3 events + Lambda.
7. **Backup & Disaster Recovery** — Replication and restoration testing.
8. **Cost Control & Compliance** — Budgets, alerts, and documentation.

Each phase is treated as a real-world infrastructure delivery pipeline, including all issues encountered and solutions applied.

---

## Step 1: Backend Cloud Infrastructure (EC2 Instance Deployment)

### Objective

Provision a secure EC2 instance in AWS to simulate a backend server. This forms the compute core of the application.

### Service Overview: Amazon EC2

Amazon EC2 (Elastic Compute Cloud) provides scalable virtual servers. This service was chosen to emulate a backend microservice instance accessible via HTTP and secured via SSH.

### Configuration Summary

| Parameter      | Value                     |
| -------------- | ------------------------- |
| Instance Name  | `cool-delivery-backend` |
| AMI            | Amazon Linux 2            |
| Instance Type  | `t2.micro`              |
| Key Pair       | `ogc-key.pem`           |
| VPC / Subnet   | Default VPC, eu-west-1b   |
| Public IP      | Enabled                   |
| Security Group | `launch-wizard-1`       |
| Inbound Rules  | SSH (22), HTTP (80)       |
| Storage        | 8 GB gp2, not encrypted   |

### Deployment Steps

1. Navigate to **EC2 > Instances > Launch Instance**
2. Select **Amazon Linux 2** AMI (Free Tier eligible)
3. Choose **t2.micro** as instance type
4. Create or reuse **Key Pair** `ogc-key.pem`
5. Use default **VPC and Subnet** (auto-selected)
6. Create **Security Group** `ogc-sg`:
   * SSH (TCP/22) from 0.0.0.0/0
   * HTTP (TCP/80) from 0.0.0.0/0
7. Leave storage default (8 GiB)
8. Click **Launch Instance** and wait until **Running**

### Security Justifications

| Component   | Security Measure                           |
| ----------- | ------------------------------------------ |
| Key Pair    | SSH login with RSA key, no password use    |
| SG Port 80  | Required for frontend connection via HTTP  |
| SG Port 22  | Admin connection (to be tightened in prod) |
| Public IP   | Enabled for visibility/testing             |
| No IAM Role | Enforces minimal privilege by default      |

### Evidences

* `1.png`: EC2 dashboard with instance name `cool-delivery-backend` and IP `34.252.181.236`
* `2.png`: Security group config — ports 22 and 80 open from `0.0.0.0/0`
* `3.png`: Network tab — shows VPC `vpc-028489f8c8aa672e6`, subnet `eu-west-1b`

---

## Step 2: Secure Frontend Hosting (S3 + CloudFront + AWS WAF)

### Objective

Deploy a publicly accessible static frontend for the Cool Delivery application, using Amazon S3 as the storage layer, CloudFront as a CDN layer with enforced HTTPS, and AWS WAF to filter malicious requests (e.g., SQL injections).

### Service Overview

* **Amazon S3** : Object storage used to host the static frontend (HTML/CSS).
* **CloudFront** : Global CDN to serve content over HTTPS with low latency.
* **AWS WAF** : Web application firewall attached to CloudFront for request inspection.

### Configuration Summary

| Component      | Value / Status                                              |
| -------------- | ----------------------------------------------------------- |
| Bucket Name    | `cool-delivery-frontend`                                  |
| Region         | `eu-west-1`(Ireland)                                      |
| Static Hosting | Enabled                                                     |
| Public Access  | `Block Public Access`disabled, policy allows public reads |
| Index Document | `index.html`                                              |
| CloudFront     | Domain:`d2k3yhy4blquvh.cloudfront.net`                    |
| HTTPS          | Redirect HTTP to HTTPS                                      |
| WAF            | Web ACL `cool-delivery-waf`with SQLi block rule           |

### Deployment Steps

#### 2.1 Create a Public S3 Bucket

* Go to **S3 > Create bucket**
* Name: `cool-delivery-frontend`
* Region: `eu-west-1`
* Uncheck **Block all public access**
* Confirm warning and proceed

#### 2.2 Upload and Host `index.html`

* Create a simple HTML page (sample provided in appendix)
* Upload to the bucket
* Enable **Static website hosting**
  * Index document: `index.html`
* Save endpoint URL (e.g., `http://cool-delivery-frontend.s3-website-eu-west-1.amazonaws.com`)

#### 2.3 Create a CloudFront Distribution

* Origin: S3 website endpoint (not ARN)
* Viewer protocol policy: Redirect HTTP to HTTPS
* Default root object: `index.html`
* Click **Create Distribution**

#### 2.4 Attach a Web ACL with SQLi Rule

* Go to **WAF & Shield > Web ACLs > Create Web ACL**
* Name: `cool-delivery-waf`
* Region: Global (CloudFront scope)
* Resource: Link to CloudFront distribution
* Add rule:
  * Managed rule builder > SQLi match statement
  * Inspect: All query parameters
  * Action: Block
* Deploy Web ACL

### Security Justifications

| Component  | Justification                                                     |
| ---------- | ----------------------------------------------------------------- |
| Public S3  | Needed to serve static content, secured by explicit bucket policy |
| CloudFront | Provides HTTPS, DDoS mitigation, caching                          |
| WAF        | Detects and blocks SQL injection and other common web attacks     |

### Evidences

* `4.png`: Bucket settings with static website hosting enabled
* `5.png`: `index.html` present in the bucket
* `6.png`: Website endpoint accessible over HTTP
* `7.png`: CloudFront distribution with HTTPS redirect and domain
* `8.png`: WAF ACL with SQL injection rule attached

---

# Step 3: Monitoring & Threat Detection (CloudTrail, CloudWatch, GuardDuty)

### Objective

Implement observability and detection mechanisms to monitor AWS activity and identify potential threats. This includes tracking API calls, system metrics, and detecting suspicious behaviors.

### Services Overview

* **CloudTrail** : Logs API activity across AWS services
* **CloudWatch** : Monitors system metrics and enables alarms
* **GuardDuty** : Detects unauthorized and malicious activity using machine learning

### Configuration Summary

| Component        | Value / Configuration                              |
| ---------------- | -------------------------------------------------- |
| CloudTrail Trail | `ogc-cloudtrail`(all regions, Read+Write events) |
| S3 Logs Bucket   | `ogc-logs-trail`with SSE-S3 encryption           |
| GuardDuty        | Enabled with default settings                      |
| CloudWatch Alarm | CPU Utilization > 50% for 1 minute on EC2 instance |

### Deployment Steps

#### 3.1 Enable CloudTrail

* Go to **CloudTrail > Trails > Create trail**
* Name: `ogc-cloudtrail`
* Apply to all regions: Yes
* Events: Read + Write
* Create new S3 bucket: `ogc-logs-trail`
* Enable SSE-S3 encryption
* Click **Create Trail**

#### 3.2 Enable GuardDuty

* Go to **GuardDuty > Get Started**
* Click **Enable GuardDuty**
* Leave default configurations
* Wait for findings to populate

#### 3.3 Create CloudWatch Alarm

* Go to **CloudWatch > Alarms > Create Alarm**
* Select EC2 metrics > CPUUtilization for backend instance
* Define threshold: > 50% for 1 minute
* Optional: Create SNS topic or just alert
* Click **Create Alarm**

### Security Justifications

| Component  | Justification                                             |
| ---------- | --------------------------------------------------------- |
| CloudTrail | Provides full audit trail of user and API actions         |
| GuardDuty  | Detects reconnaissance and threats (e.g. SSH brute force) |
| CloudWatch | Real-time monitoring for system health and alerts         |

### Evidences

* `9.png`: Trail summary showing CloudTrail active
* `10.png`: GuardDuty dashboard with service enabled
* `11.png`: CloudWatch metrics for EC2 instance
* `12.png`: Alarm configuration (CPU Utilization)
* `13.png`: Alarm state visualization

---

# Step 4: Identity & Access Management (IAM)

### Objective

Implement robust identity and access management to enforce the principle of least privilege and secure administrative access.

### Service Overview

* **IAM (Identity and Access Management)** is AWS's centralized service for managing users, groups, roles, and access policies.
* This step introduces a secure administrator user with enforced MFA and scoped permissions via a group policy.

### Configuration Summary

| Component       | Value / Description                  |
| --------------- | ------------------------------------ |
| IAM User        | `admin-ben`                        |
| IAM Group       | `cloud-admins`                     |
| Policy Attached | `AdministratorAccess`(AWS managed) |
| MFA Enabled     | Virtual MFA (Google Authenticator)   |

### Deployment Steps

#### 4.1 Create IAM Group

* Go to **IAM > Groups > Create group**
* Name: `cloud-admins`
* Attach policy: `AdministratorAccess`
* Create group

#### 4.2 Create IAM User

* IAM > Users > Add user
* Username: `admin-ben`
* Access type: **AWS Management Console access**
* Assign to group: `cloud-admins`
* Auto-generate password and require reset

#### 4.3 Enforce MFA

* Click on user `admin-ben`
* Go to **Security credentials** tab
* Under **Multi-Factor Authentication (MFA)** click **Assign MFA device**
* Choose **Virtual MFA device**
* Scan the QR code with Google Authenticator (proof: screenshot from mobile)
* Enter two consecutive codes and confirm

### Security Justifications

| Component     | Justification                                             |
| ------------- | --------------------------------------------------------- |
| IAM Group     | Simplifies privilege management via policy inheritance    |
| Admin Policy  | Grants full access for infrastructure setup/testing       |
| MFA           | Enforces second factor, mitigating credential compromise  |
| Console Login | Required for GUI-based tasks during project demonstration |

### Evidences

* `20.png`: IAM dashboard with user `admin-ben`
* `21.png`: Group `cloud-admins` with attached policy
* `22.png`: MFA device successfully activated and registered

---

## Step 5: System Hardening (Firewalls, Agents, Auditing)

### Objective

Reinforce the security of the EC2 compute instance through service minimization, active monitoring, and system-level protection mechanisms.

### Configuration Summary

| Component         | Value / Configuration                                       |
| ----------------- | ----------------------------------------------------------- |
| Operating System  | Amazon Linux 2                                              |
| Firewall          | firewalld with `ssh`,`http`, and `https`services only |
| Security Agents   | `fail2ban`,`auditd`,`rkhunter`,`lynis`              |
| Disabled Services | `postfix`,`rpcbind`                                     |

### Deployment Steps

#### 5.1 Configure Firewall (firewalld)

* Check firewalld status: `sudo systemctl status firewalld`
* If not running, enable and start it: `sudo systemctl enable --now firewalld`
* Open necessary ports:
  ```bash
  sudo firewall-cmd --permanent --add-service=ssh
  sudo firewall-cmd --permanent --add-service=http
  sudo firewall-cmd --permanent --add-service=https
  sudo firewall-cmd --reload
  ```
* Verify rules: `sudo firewall-cmd --list-all`

#### 5.2 Install and Configure Security Tools

* `fail2ban` (installed via EPEL):
  ```bash
  sudo amazon-linux-extras enable epel
  sudo yum install -y fail2ban
  sudo systemctl enable --now fail2ban
  ```
* `auditd`:
  ```bash
  sudo yum install -y audit
  sudo systemctl enable --now auditd
  ```
* `rkhunter`:
  ```bash
  sudo yum install -y rkhunter
  sudo rkhunter --update
  sudo rkhunter --check
  ```
* `lynis`:
  ```bash
  sudo yum install -y lynis
  sudo lynis audit system
  ```

#### 5.3 Disable Unused Services

* Stop and disable unnecessary services:
  ```bash
  sudo systemctl disable --now postfix rpcbind
  ```

### Security Justifications

| Component         | Justification                                             |
| ----------------- | --------------------------------------------------------- |
| firewalld         | Reduces attack surface by restricting network access      |
| fail2ban          | Prevents brute-force SSH attacks                          |
| auditd            | Records system-level events for compliance                |
| rkhunter/lynis    | Performs rootkit and security audit                       |
| Disabled services | Eliminates unnecessary and potentially vulnerable daemons |

### Evidences

* `5.png`: firewalld active with necessary services
* `6.png`: fail2ban, auditd, rkhunter installed and active
* `7.png`: `rkhunter` scan showing no rootkits found
* `8.png`: `lynis` scan results, hardening index = 65

---

# Step 6: Advanced Logging (S3 Event Notification + Lambda)

### Objective

Implement serverless logging automation by leveraging Amazon S3 events to trigger AWS Lambda functions. This configuration increases observability and supports custom alerting pipelines.

### Configuration Summary

| Component        | Configuration Detail                            |
| ---------------- | ----------------------------------------------- |
| S3 Source Bucket | `cool-delivery-frontend`                      |
| Event Trigger    | On object creation with prefix `images/`      |
| Lambda Function  | Custom Python function triggered on .jpg upload |
| Permissions      | IAM role with S3 read and Lambda execution      |

### Deployment Steps

#### 6.1 Create Event Notification on S3

* Go to **S3 > cool-delivery-frontend > Properties**
* Under  **Event notifications** , click **Create event notification**
* Name: `ImageUploadTrigger`
* Event type: `PUT`
* Prefix: `images/`
* Suffix: `.jpg`
* Destination: **Lambda function** → Select the created function

#### 6.2 Create Lambda Function (Python)

Example handler:

```python
import json
def lambda_handler(event, context):
    print("New file uploaded:", json.dumps(event))
    return {
        'statusCode': 200,
        'body': json.dumps('File processed successfully!')
    }
```

* Runtime: Python 3.12
* IAM Role: Create role with `AmazonS3ReadOnlyAccess` and `AWSLambdaBasicExecutionRole`

#### 6.3 Permissions Adjustment

* Ensure bucket policy allows invocation by the Lambda service
* Confirm role trust policy allows S3 service to invoke Lambda

### Evidence

* `10.png`: S3 bucket configured with event notification
* `11.png`: Lambda function created and visible in AWS Lambda Console
* `12.png`: Lambda permissions properly set
* `13.png`: S3 to Lambda link operational

### Security & Operational Justification

| Mechanism           | Justification                                           |
| ------------------- | ------------------------------------------------------- |
| S3 Event Triggers   | Enable near real-time alerting on object actions        |
| Lambda Execution    | Serverless, scalable response mechanism for file events |
| IAM Role Separation | Enforces least privilege for S3 and Lambda interactions |

---

# Step 7: Backup & Disaster Recovery (S3 Cross-Region Replication)

### Objective

Ensure high availability and durability of critical static assets through automated backup mechanisms. We leverage AWS S3 Cross-Region Replication to simulate disaster recovery capabilities.

### Configuration Summary

| Component          | Configuration Detail                             |
| ------------------ | ------------------------------------------------ |
| Source Bucket      | `cool-delivery-frontend`                       |
| Destination Bucket | `cool-delivery-backup`                         |
| Region             | `eu-west-1`(Ireland)                           |
| Replication Rule   | Prefix:`images/`, Status: Enabled              |
| IAM Role           | Auto-created replication role with correct trust |

### Deployment Steps

#### 7.1 Create Backup Bucket

* Go to **S3 > Create bucket**
* Name: `cool-delivery-backup`
* Region: Same as source (eu-west-1)
* Block all public access: Enabled
* Default encryption: SSE-S3

#### 7.2 Enable Replication on Source Bucket

* Go to **S3 > cool-delivery-frontend > Management tab**
* Click **Create replication rule**
* Rule Name: `ImagesReplication`
* Prefix: `images/`
* Destination: `cool-delivery-backup`
* IAM Role: Allow auto-creation
* Save rule

### Evidence

* `14.png`: Destination bucket `cool-delivery-backup` created
* `15.png`: Replication rule targeting prefix `images/`
* `16.png`: Replication rule active and policy attached

### Security & Operational Justification

| Mechanism          | Justification                              |
| ------------------ | ------------------------------------------ |
| S3 Replication     | Increases durability and fault tolerance   |
| Encryption at rest | Maintains data confidentiality (SSE-S3)    |
| IAM Role Control   | Ensures scoped permissions for replication |

---

# Step 8: Billing and Cost Awareness

## 8.1 Cost Monitoring Overview

Throughout the Secure Cloud Architecture project, continuous cost monitoring was implemented via the AWS Billing and Cost Management dashboard.

At the end of the project, the following observations were made:

* **Current month-to-date cost (April 2025):** **$2.66**
* **Forecasted total monthly cost:** **Not available** (data missing due to limited activity duration)
* **Previous month total cost:** **$0.00**

## 8.2 Services Generating Costs

The primary AWS services responsible for cost generation were:

| Service                            | Purpose                                  |
| ---------------------------------- | ---------------------------------------- |
| Amazon Simple Storage Service (S3) | Hosting the static frontend (index.html) |
| AWS CloudTrail                     | Monitoring and logging API activities    |
| AWS WAF                            | Web application firewall protection      |
| AWS Key Management Service (KMS)   | Default encryption and key management    |
| Taxes                              | Applicable VAT charges                   |

## 8.3 Billing Breakdown Evidence

Billing evidence was captured from the AWS console:

* **Overall Cost Management Dashboard:**
  * Total cost visualized by service.
  * Warning for budget exceeded by small amounts.
* **Cost Explorer Report:**
  * No cost history available for previous months (project deployed recently).
  * Real-time monitoring enabled.

*(33.png, 34.png)*

## 8.4 Budget Status and Anomalies

During the project, a budget alert was triggered because the **monthly billing budget** was slightly exceeded due to:

* Additional storage usage on S3.
* WAF rules costs not initially accounted for.

However, no cost anomaly was detected (AWS anomaly detector remained green).

## 8.5 Best Practices for Future Projects

> **Best Practice Warning:**
>
> It is strongly recommended to implement active budget monitoring mechanisms when using AWS services:
>
> * Create monthly budgets with email alerts.
> * Enable AWS Cost Anomaly Detection to catch unexpected spikes.
> * Regularly consult Cost Explorer to optimize usage and avoid overcharges.
> * Use Free Tier services whenever possible for educational projects.
>
> This strategy helps in maintaining cost predictability and avoiding unexpected billing issues.

---

# Step 9 — Delivery & Deployment (GitHub + Docker)

## Objective

Ensure a **professional and reproducible delivery** of the frontend component by using **Docker containerization** and hosting deployment artifacts on  **GitHub** . This method guarantees portability, quick deployment, and aligns with modern DevOps best practices.

## 9.1 Repository creation

A GitHub repository was created to store:

* Static web assets (`index.html`).
* A `Dockerfile` to containerize the website.
* A `README.md` containing deployment instructions.

Example repository structure:

```plaintext
secure-cloud-frontend/
├── Dockerfile
├── README.md
└── website/
    └── index.html
```

### 9.2 Docker containerization

A lightweight container was created using the `nginx:alpine` image to serve the static content.

**Dockerfile content:**

```Dockerfile
FROM nginx:alpine
COPY website/ /usr/share/nginx/html/
EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

* `FROM nginx:alpine`: Use a minimal web server image.
* `COPY`: Transfer website files into the container.
* `EXPOSE 80`: Expose the HTTP port.
* `CMD`: Start the server automatically.

### 9.3 Deployment procedure

To deploy the project locally or on any compatible environment:

```bash
# Clone the GitHub repository
git clone https://github.com/<your-github-username>/secure-cloud-frontend.git
cd secure-cloud-frontend

# Build the Docker image
docker build -t cool-delivery-frontend .

# Run the container
docker run -d -p 8080:80 cool-delivery-frontend
```

Access the website at:

 `http://localhost:8080`

### 9.4 Delivery Proofs

* GitHub repository URL (public access).
* Screenshots of:
  * GitHub files.
  * Docker image built.
  * Running container.
  * Website accessible via `localhost:8080`.

## Key Advantages

| Aspect                    | Description                                            |
| ------------------------- | ------------------------------------------------------ |
| **Speed**           | Full deployment in under 2 minutes                     |
| **Portability**     | The frontend can be deployed on any system with Docker |
| **Version control** | Full traceability of changes via GitHub                |
| **Professionalism** | Follows DevOps and industry standards                  |

## Best Practices

* Always push **working code** to GitHub.
* Build **minimal Docker images** for security and performance.
* Document **clear deployment instructions** for users and administrators.

---

# Final Remarks

The secure cloud architecture presented in this project demonstrates a comprehensive understanding of AWS services, layered security, and operational best practices. Despite access constraints, each step has been adapted, documented, and justified to the fullest extent.

All configuration choices, challenges, and resolutions have been included for educational and auditing purposes.

The project concludes with a functional, secure, and scalable cloud environment, documented with screenshots, configuration tables, and professional commentary. The output is structured to meet academic standards for a grade A deliverable.
